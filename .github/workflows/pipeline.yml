name: Model Pipeline

on:
  workflow_run:
    workflows: ["Train Model"]
    types:
      - completed
  schedule:
    - cron: '0 0 * * 1'  # Run every Monday at midnight
  workflow_dispatch:  # Enable manual triggers

permissions:
  contents: write
  pull-requests: write
  issues: write
  checks: write
  deployments: write
  statuses: write

jobs:
  data_processing:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install data processing dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy scikit-learn torch datasets transformers
          
      - name: Process and validate data
        run: |
          python scripts/data_processing.py --validate
          python scripts/data_augmentation.py
          
      - name: Upload processed data
        uses: actions/upload-artifact@v3
        with:
          name: processed-data
          path: data/processed/

  model_evaluation:
    needs: data_processing
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Download processed data
        uses: actions/download-artifact@v3
        with:
          name: processed-data
          path: data/processed/
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install evaluation dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov mlflow wandb
          
      - name: Run model evaluation
        env:
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
        run: |
          python scripts/evaluate_model.py --all-metrics
          python scripts/generate_evaluation_report.py
          
      - name: Upload evaluation results
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-results
          path: reports/evaluation/

  documentation:
    needs: model_evaluation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Download evaluation results
        uses: actions/download-artifact@v3
        with:
          name: evaluation-results
          path: docs/benchmarks/
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install documentation dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mkdocs mkdocs-material pymdown-extensions
          
      - name: Update benchmark documentation
        run: python scripts/update_benchmark_docs.py
          
      - name: Build documentation
        run: mkdocs build
        
      - name: Check links
        run: |
          pip install linkchecker
          linkchecker ./site/
          
      - name: Deploy documentation
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./site
